---
title: "Notes on Confidence Intervals"
author: "CSC 400, Spring 2024"
date: "`r Sys.Date()`"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 2
  html_document:
    #toc: true
    #toc_float: true
    #toc_collapsed: true
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "docs", output_file = "index.html") })
#runtime: shiny
resource_files:
- computation/app.R
- mean/app.R
- sampling/app.R
- proportion/app.R
---

```{r setup, include=FALSE}
## this document is published to:
## https://homer.shinyapps.io/stoveteam/
library(tidyverse)
library(readxl)
library(shiny)
library(nlme)
## for menas app:
##library(bslib)
##library(bsicons)
## knitr options:
knitr::opts_chunk$set(
  echo = FALSE,
  message = FALSE,
  warning = FALSE
)

## utility function to get info on a single house:
get_house <- function(i) {
  vals <- read_excel(
    "st_files/For Review_Ret_Justa_July KPT Complete_KPT_4day (1).xlsx", 
    range = "I15:L15",
    sheet = paste0("HH", i, " Data"),
    col_names = FALSE
  ) %>% 
    as.matrix() %>% 
    t() %>% 
    .[,1]
  vals <- vals[!is.na(vals)]
  data.frame(
    house = rep(i, length(vals)),
    wood = vals
  )
}

## data frame with info on all houses.
## each row is a house on a day:
all_meas <- 
  map_dfr(factor(1:16), get_house) %>% 
  group_by(house) %>% 
  mutate(mean_percap = mean(wood)) %>% 
  mutate(deviation = wood - mean_percap)
```

# Introduction

Coming soon!



# Confidence Intervals for a Proportion

There are many methods for computing a confidence interval for a population proportion $p$.  The document *CDM-EB67-A06-GUID* appears to assume (see Equation 7 near the bottom of page 71) the use of what is known as the *Wald Interval*:

$$\left(\hat{p} - z^* \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}, \hat{p} - z^* \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}\right),$$
where:

* $\hat{p} = X/n$ is the *sample proportion* (the number $X$ of successes in the sample divided by the sample size $n$);
* $z^*$ is the percentile of the standard normal distribution appropriate to the desired level of confidence (for a 90%-confidence interval this is approximately `r round(qnorm(0.95), 3)`).

**Note**:  Equation 7 actually included an attempt at the *finite population correction factor* but got the factor slightly wrong.  The interval with correction factor should be:

$$\left(\hat{p} - z^* \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}\sqrt{\frac{N-n}{N-1}}, \hat{p} - z^* \sqrt{\frac{\hat{p}(1 - \hat{p})}{n}}\sqrt{\frac{N-n}{N-1}}\right),$$
where $N$ is the number of households that were provided with stoves.

Wald intervals don't have the best statistical properties:  for smaller sample sizes, and for population proportions that are near 0 or near 1, the nominal level of confidence of the intervals can differ significantly from their actual levels.  In the situation of our study the sample size is not very large, so we will recommend a more sophisticated method.

A Wilson interval with a finite population correction would be a fine choice, as it has been demonstrated to have good statisitcal properties at small sample sizes, provided that $p$ is not very close to 0 or 1.  (See Seung-Chun Lee, "Confidence Intervals for a Proportion in Finite-Poluation Sampling", *Communications of the Korean Statistical Society*, 2009, Vol. 16, no. 3, pp. 501-509.) The formula for the interval is the rather daunting expression:

$$\tilde{p}^*\pm z^*\frac{\sqrt{1 - f^*}}{\tilde{n}^*}\sqrt{n\hat{p}(1-\hat{p}) + (1-f^*)(z^*)^2/4},$$
where:

* $n$ is the sample size;
* $\hat{p}$ is the sample proportion (number of successes $X$ in the sample divided by $n$);
* $z^*$ is the percentile of the standard normal distribution that corresponding to the desired level of confidence (approximately 1.645 for a 90%-confidence interval);
* $f^* = (n-1)/(N-1)$, where $N$ is the size of the population from which the sample is drawn;
* $\tilde{n}^*= n + (1-f^*)(z^*)^2$;
* $\tilde{p}^* = \left(X + (1-f^*)(z^*)^2/2\right)/\tilde{n}^*$.

```{r}
wilson_corrected <- function(x, n, N, level) {
  z <- qnorm((1 + level) / 2)
  p_hat <- x / n
  f <- (n - 1) / (N - 1)
  n_t <- n + (1 - f) * z^2
  p_t <- (x + (1 - f) * z^2 / 2) / n_t
  margin <- z*sqrt(1-f)*sqrt(n*p_hat*(1-p_hat)+(1-f)*z^2/4)/n_t
  interval <- c(
    lower = p_t - margin,
    upper = p_t + margin
  )
  list(
    ci = interval,
    margin = margin
  )
}

res_w <- wilson_corrected(
  x = 37,
  n = 65,
  N = 500,
  level = 0.90
)
```


For example, if we sample $n=65$ households at random from a population of $N=500$ households that are provided with stoves and we find that $X=37$ are still using their stoves, then a 90%-confidence interval for $p$, the proportion of all 500 households that still use their stoves would extend from `r round(res_w$ci[1], 3)` to `r round(res_w$ci[2], 3)`, with the margin of error being `r round(res_w$margin, 4)`.  (By happenstance this turns out to be nearly the same as the corrected Wald interval, but we'll stick with it in spite of the extra effort.)

## Sample Size

Our estimate the proportion of households in the population where the stove is still in use is required to have a minimum precision of 0.10.

From Section 12(a) of the document *CDM-EB50-A30-STAN* we can infer a definition of precision:

>As a relative unit when the parameter of interest is a proportion (or a percentage) For example, ± 10 per cent in relative units means that the interval around a proportion value of 70 per cent is 63 per cent to 77 per cent. A proportion can describe either of the two possible scenarios of the success rate (p) or the failure rate (1−p), for example (i) cookstove still operational or (ii) cookstove no longer operational. The project participants or the coordinating/managing entity may use the larger of the two proportions in the sample size calculation, that is (p) or (1−p), in any of the monitoring periods during the crediting period without having to revise the monitoring plan.

We see that precision should be calculated as:

$$\text{precision} = \frac{\text{margin of error}}{\max(\hat{p}, 1 - \hat{p})}.$$

Thus in our example where we sample $n=65$ households at random from a population of $N=500$ households that are provided with stoves and find that $X=37$ are still using their stoves, we have $\hat{p} = 37/65 \approx 0.569$ so the maximum of $\hat{p}$ and $1-\hat{p}$ is 0.569 and the precision would be:

$$\frac{\text{margin of error}}{0.569} \approx \frac{0.0927}{0.569} \approx 0.163,$$
a good bit higher than our target.  We will have to take a larger sample.

We would like to derive a formula for the sample size $n_d$ required for the resulting confidence interval to have a precision not exceeding 0.10.  In order to derive the formula we must assume a fairly simple fornula for the margin of error, so we'll use the margin of error for Wald intervals, even if the confidence intervals we actually make are based on another method.

So we are looking for a value of $n_d$ such that:

$$\frac{z^* \sqrt{\frac{\hat{p}(1 - \hat{p})}{n_d}}\sqrt{\frac{N-n_d}{N-1}}}{\max(\hat{p}, 1 - \hat{p})} \leq 0.10.$$
Of course, we won't know $\hat{p}$ until we actually take our samnple, so we need to replace occurences of $\hat{p}$ in the above inequalities with reasonable approximations.

Now the precision is larger (i.e., "worse") when the denominator $\max(\hat{p}, 1 - \hat{p}$ is smallest, and this occurs when $\hat{p} = 0.50$.  Also the precision is larger when the numerator is largest, and this occurs when $\hat{p}(1-\hat{p})$ is largest, and this also occurs when $\hat{p} = 0.50$.  Therefore if we replace $\hat{p}$ with 0.50, we get an inequality

$$\frac{z^* \sqrt{\frac{0.5(1 - 0.5)}{n_d}}\sqrt{\frac{N-n_d}{N-1}}}{\max(0.5, 1 - 0.5)} = \frac{z^*\sqrt{N-n_d}}{\sqrt{n_d(N-1)}}\leq 0.10.$$
which, when solved for $n_d$, results in a sample size that is conservative in the sense that it is liable to be larger than needed.

Solving the inequality for $n_d$, we get:

$$n_d \geq \frac{(z^*)^2N}{0.10^2(N-1) +(z^*)^2}.$$

This agrees with the formula suggested on page 28 of *CDM-EB50-A30-STAN*, when one replaces the $p$ in that formula with 0.50.

For example, if we plan to make a 90%-confidence interval and the size of the population is $N=500$, then the sample size needs to be at least

$$\frac{1.645^2\times 500}{0.10^2\times 499 +1.645^2} \approx 176.$$


<!-- Finn does this app-->

```{r proportion, echo=FALSE}
# shinyAppDir(
#   appDir = "proportion",
#   options = list(
#     width = "100%", height = 550
#   )
# )
```


# Confidence Intervals for the Mean

Coming soon!
 
<!-- Rhys does this app-->


```{r mean, echo=FALSE}
# shinyAppDir(
#   appDir = "mean",
#   options = list(
#     width = "100%", height = 550
#   )
# )
```





# Confidence Intervals for the Mean of Household Means

## A Parametric Approach

We imagine a large population of households.  Each household $h$ in the population has a mean per-capita daily usage of wood, which we will denote $\mu_h$.  Of course $\mu_h$ varies from one household to another.  Let $\mu$ denote the mean of all these mean per-capita daily usages.  $\mu$ is the number that we are trying to estimate and for which we desire to form a confidence interval, based upon the data we have collected.  (**Note:** See the Appendix for more on why this is the appropriate parameter.)

We make the assumption that the population of $\mu_h$-values is normally distributed, with mean $\mu$ and some unknown standard deviation $\sigma_b$.  (The subscript $b$ calls to mind that the mean daily per-capita usage varies *between* households, i.e., from one household to another.)

We select $n$ households at random from our population, and visit each household.  Let $i$ be any number from 1 to $n$, and consider household $i$ (the $i$-th household selected for study).  When we arrive at household $i$, we are of course not provided its $\mu_i$ value.  Instead we must estimate $\mu_i$ by measuring the per-capita usage for each of $J_i$ days (in the study conducted, $J_i$ is sometimes 3 and sometimes 4).  We get $J_i$ measurements:

$$X_{i1}, X_{i2}, \ldots, X_{iJ_i}.$$
We compute the mean of these measurements:

$$\bar{X}_i = \frac{\sum_{j=1}^{J_i}X_{ij}}{J_i}.$$
to estimate $\mu_i$.

Now there is variability in this estimator $\bar{X}_i$, because the actual per-capita usage in a single household varies from day to day.  We make an important simplifying assumption, namely:  that the one-day per-capita usage for the household is normally distributed, with mean $\mu_i$ and some unknown standard deviation $\sigma_w$. (The subscript $w$ in the notation calls to mind that the variability is "within" a fixed household from day to day.) Importantly, we are assuming that $\sigma_w$ is the *same* for all households in the population.

We would then estimate $\mu$ by computing the mean of the $n$ household means:

$$\overline{\overline{X}} = \frac{\sum_{i=1}^n \bar{X}_i}{n}$$

Note that there are *two* sources of variability in the above estimator:

* variability in mean daily per-capita usage from one household to another, expressed by the unknown $\sigma_b$;
* variability in per-capita usage from day to day, *within* a fixed household, expressed by the unknown $\sigma_w$.

In fact, probability theory tells us that the distribution of $\overline{\overline{X}}$ is normal, with mean $\mu$ and standard deviation:

$$\frac{\sqrt{\sigma^2_b +\frac{\sigma^2_w\left(1/J_1+\ldots+1/J_n\right)}{n}}}{\sqrt{n}}.$$

Now let us turn to the task of making confidence intervals for $\mu$.  To this end, define the *between-sum of squares*:

$$SS_b = \sum_{i=1}^n \left( \overline{\overline{X}} - \bar{X}_i \right)^2.$$

A bit of standard statistical theory tells us that if all households were measured for the same number $J$ of days, then the random variable:

$$T = \frac{\overline{\overline{X}} - \mu}{\sqrt{\frac{SS_b}{n(n-1)}}}$$
would have a t-distribution, with degrees of freedom equal to $n-1$.  (Interestingly, the degrees of freedom are independent of $J$.)

One then derives, in a way familiar to statisticians, confidence intervals of the form:

$$\left(\overline{\overline{X}} - t_{n-1}^*\sqrt{\frac{SS_b}{n(n-1)}},\, \overline{\overline{X}} + t_{n-1}^*\sqrt{\frac{SS_b}{n(n-1)}}\right),$$

where $t_{n-1}^*$ is the quantile of the t-distribution with $n-1$ degrees of freedom that is appropriate for the desired level of confidence.

The above formula assumes that the population-size is "infinite".  In fact, if the population is of some finite size $N$, then to obtain an exact interval one would employ the *finite-poulation correction factor*

$$\sqrt{\frac{N-n}{N-1}}$$

to the margin of error, obtaining:

$$\left(\overline{\overline{X}} - t_{n-1}^*\sqrt{\frac{SS_b}{n(n-1)}}\sqrt{\frac{N-n}{N-1}},\, \overline{\overline{X}} + t_{n-1}^*\sqrt{\frac{SS_b}{n(n-1)}}\sqrt{\frac{N-n}{N-1}}\right).$$
The correction factor need only be incorporated when the sample size $n$ is a substantial fraction of the size of the population.

Clearly, though,  there is an obstacle to using either of the above intervals, since in our study not all households were measured for the same number of days:  the number of days was sometimes 3 and sometimes 4.  Hence the random variable $T$ will not, for us, have an exact t-distribution.  We won't be able to derive confidence intervals with coverage-properties that are known exactly.

We can take a conservative approach, however.  Suppose that we were to simply throw away the final measurement for any day that had four measurements.  Then the number $J$ above could be set to three, and from the remaining data we could compute exact confidence intervals.

```{r}
compute_ci_1 <- function(data, level, use = NULL, N = NULL) {
  if (is.null(use)) {
    house_info <-
      data %>% 
      group_by(house) %>% 
      summarize(mean = mean(wood))
  } else {
    house_info <-
      data %>% 
      group_by(house) %>% 
      slice_head(n = use) %>% 
      summarize(mean = mean(wood))
  }
  n <- nrow(house_info)
  multiplier <- qt((1 + level) / 2, df = n - 1)
  sample_mean <- mean(house_info$mean)
  ss_between <- sum((sample_mean - house_info$mean)^2)
  margin <- multiplier * sqrt(ss_between / (n * (n - 1)))
  if (!is.null(N)) {
    ## apply finite-population correction factor
    margin <- margin * sqrt((N - n) / (N - 1))
  }
  list(
    point_estimate = sample_mean, 
    margin = margin,
    interval = c(
      sample_mean - margin,
      sample_mean + margin
    )
  )
}

## try it out:
res <- compute_ci_1(
  data = all_meas, 
  level = 0.90,
  use = 3
)

res_all <- compute_ci_1(
  data = all_meas, 
  level = 0.90
)

res_all2 <- compute_ci_1(
  data = all_meas, 
  level = 0.90,
  N = 500
)
```


When we throw out the fourth-day measurements and make a confidence interval based on the above formula, where each household has three measurements, we find that:

* The point-estimate of $\mu$ is `r round(res$point_estimate, 3)`.
* The 90%-confidence interval extends from `r round(res$interval[1], 3)` to `r round(res$interval[2], 3)`.
* The margin of error for the above interval is `r round(res$margin, 3)`.


When we keep all of the measurements, we find that:

* The point-estimate of $\mu$ is `r round(res_all$point_estimate, 3)`.
* The 90%-confidence interval extends from `r round(res_all$interval[1], 3)` to `r round(res_all$interval[2], 3)`.
* The margin of error for the above interval is `r round(res_all$margin, 3)`.

As an example of the use of the finite population correction factor, suppose that there are 500 households in the population.  Then when we keep all of the data and use the correction factor the interval shrinks a bit, extending from `r round(res_all2$interval[1], 3)` to `r round(res_all2$interval[2], 3)`.

## A Caution

Recall that one of our assumptions was that the underlying population of mean per-capita household usages was normally distributed.  In practice, no population distribution is ever exactly normal.  We can take some comfort from statistical theory, which assures us that even if the population is not normal, the actual coverage-properties of our confidence intervals converge to the advertised coverage-properties as sample size increases to infinity. Nonetheless, when the sample size is small and the population distribution differs significantly from normal (especially if it is skewed in one direction or another) then there may be a significant difference between actual and advertised performance.

Our sample size is only 16 households--somewhat small--so we should plot the sample to see whether there any indication of skewness in the population.  Below is a density plot of the sample:

```{r}
house_info <-
  all_meas %>% 
  group_by(house) %>% 
  summarize(mean = mean(wood), J = n())
ggplot(house_info, aes(x = mean)) +
  geom_density(fill = "skyblue") +
  geom_rug()
```

The sample has a strong right-skew, indicating that the population could be strongly right-skewed as well.

In future studies it would be prudent to take a larger sample of households, perhaps 30 or so.  (We are likely to take a much larger sample anyway, in order to meet the required precision.)

## The Random-Effect Approach

Our problem may also be viewed as a very special case of a linear random-effects model.  Viewing the problem in this way and using the R-package **nlme**, we get the following results:

```{r}
mod <- nlme::lme(wood ~ 1, random = ~ 1 | house, data = all_meas)
res_lme <- intervals(mod, level = 0.90)
```


* The point estimate of $\mu$ is `r round(res_lme$fixed[1,"est."], 3)`
* The 90%-confidence interval extends from `r round(res_lme$fixed[1,"lower"], 3)` to `r round(res_lme$fixed[1,"upper"], 3)`.

## Simulation Studies

We have conducted some simulation studies to get an idea of the effect of the likely skewness of the population and the non-uniformity of the sample size from household to household on the performance of confidence intervals.  In our simulations the parametric 90%-confidence intervals constructed using all of the data actually cover the mean about 89% of the time.  It should be acceptable to use this interval formula and to keep all of the data.  (In the computations for the mixed-effects model this is, in fact, done.)

## The Bootstrap

The *bootstrap* is a general strategy for statistical inference that be implemented with little or nothing in the way modeling assumptions concerning the process that generates one's data, other than that the sampling is done in a controlled and quantifiable random fashion.  It relies on the fact that, when the data are sampled randomly from the population, then its distribution is liable to resemble approximately the distribution of the population itself.

In our situation we can design a version of the bootstrap that retains the assumptions that the daily per-capita measurements in each household are normally distributed with a standatd deviation that does not depend on the household, but let go of the assumption that the mean per-capita usages for the population of households has a normal distribution.

The recipe for a 90%-confidence interval is as follows:

1. Use the deviations of the daily measurements from the mean of their respective households to estimate $s_w$, the standard deviation of the measurments within any fixed household.
1. Select a reasonably large number $B$ (we will choose $B=1999$), and perform the following process $B$ times:
    * Sample 16 households at random and with replacement, from the the sixteen households in the sample.  (This is called "re-sampling".)
    * For each household $h_i$in the re-sample, $1 \leq i \leq 16$, generate $J_i$ random values from a normal distribution with mean $\mu_i$ (the mean per-capita usage for household $h_i$) and standard deviation $s_w$, and compute the mean (denoted $\bar{x}^*_i$) of these values.  These are the "re-sampled means".
    * Compute the mean $\bar{\bar{x}}^*$ of these re-sampled means.

We now have $B$ means.  We compute the 5th and 95th percentiles of this set of numbers, and use them as the lower and upper bounds respectively of a confidence interval for $\mu$.  Bootstrap theory guarantees that as the number of households sampled increases, the probability that such an interval contains $\mu$ converges to 90%.


```{r bootstrap, cache = TRUE}
## set a seed:
set.seed(5656)
## estimate within-household variance:
sd_w <-
  all_meas %>% 
  group_by(house) %>% 
  mutate(house_mean = mean(wood)) %>% 
  summarize(n = n(), sum_sq = sum((wood - house_mean)^2)) %>% 
  mutate(deg_freedom = n - 1) %>% 
  summarize(var = sum(sum_sq * deg_freedom) / sum(deg_freedom)) %>% 
  pull(var) %>% 
  sqrt()

## get household means and measurement-numbers:
house_info <-
  all_meas %>% 
  group_by(house) %>% 
  summarize(mean = mean(wood), J = n())

## get resamples
B <- 1999
resamples <- numeric(B)
n <- nrow(house_info)
houses <- numeric(n)
for (i in 1:B) {
  resampled_houses <-
    house_info[sample(1:n), size = n]
  resampled_mean <-
    resampled_houses %>% 
    mutate(mean_rs = mean(rnorm(J, mean = mean, sd = sd_w))) %>% 
    summarize(xbar = mean(mean_rs)) %>% 
    pull(xbar)
  resamples[i] <- resampled_mean
}

## compute a percentile bootstrap interval:
level <- 0.90
interval <- quantile(resamples, probs = c(0.05, 0.95))
```

We find that:

* The approximate 90%-confidence interval for $\mu$ extends from `r round(interval[1],3)` to `r round(interval[2],3)`.

The fact that the bootstrap with its relatively loose assumptions concerning the population structure yields about the same confidence interval as the two parametric methods covered previously should give us further assurance that it is reasonable to use the parametric intervals.

## Sample Size

The document *CDM-EB50-A30-STAN* specifies that confidence interval for a mean have a precision of no more than 10%.  In Section 12(b) of the doicument, precision for a confidence interval for the mean is defined as the margin of error divided by the sample mean (multiplied by 100 to convert to a percentage).

Clearly we will want larger sample sizes in the future in order to attain the required precision.

For the desired precision, from a population of size $N$ we would require a sample size $n_d$ such that:

$$\frac{t_{n_d-1}^*\sqrt{\frac{SS_b}{n_d(n_d-1)}}\sqrt{\frac{N-n_d}{N-1}}}{\bar{\bar{x}}} \leq 0.10.$$

Of course we have not taken the new sample yet, so we do not yet know what $SS_b$ and $\bar{\bar{x}}$ are.  Hence we won't be able to determine $n$ exactly. However:

* for $SS_b/(n_d-1)$ we will substitue an estimate, namely: the value for $SS_b/(n-1)$ that we obtained in the pilot study with sample size $n$;
* for $t_{n_d-1}^*$, will use $t_{n-1}^*$ (which is a bit larger, tending to result in an underestiamte of $n_d$);
* for $\bar{\bar{x}}$ we will substitute the corresponding value that we got from the pilot study.

Our inequality now looks like:

$$\frac{t_{n-1}^*\sqrt{\frac{SS_b}{n_d(n-1)}}\sqrt{\frac{N-n_d}{N-1}}}{\bar{\bar{x}}} \leq 0.10.$$


We solve the above inequality for $n_d$, getting:

$$n_d \geq \frac{(t_{n-1}^*)^2\frac{SS_b}{n-1}N}{0.10^2(\bar{\bar{x}})^2(N-1)+(t_{n-1}^*)^2\frac{SS_b}{n-1}}.$$

If we choose not to employ a finite population correction factor, the the formula simplifies to:

$$n_d \geq \frac{(t_{n-1}^*)^2\frac{SS_b}{n-1}}{0.10^2(\bar{\bar{x}})^2}.$$

In practice we should choose a sample size significantly larger than $n_d$, as the width of the resulting interval will be subject to chance variation in the sample itself and we want to minimize the chance of that width coming out too large.


**Note**:  As a rough rule of thumb, the margin of error is inversely proportional to the square root of the number of households sampled.  Thus in order to cut the marign of error in half (for example)  we would have to sample roughly four times as many households as we did in the pilot study.

# Further Thoughts

We might be able to use the data we have to research how to strike the best balance between the number of sampled households and the number of measurements at each household.  (For example, if a researcher could equally well vist two households for two days each in not much more time than it takes to visit one household for four days, could this provide more precise estimates?)

<!-- Christara does this app-->

```{r computation, echo=FALSE}
# shinyAppDir(
#   appDir = "computation",
#   options = list(
#     width = "100%", height = 550
#   )
# )
```

# Appendix

## What Parameter Should We Estimate? {#what-parameter}

Someone might argue that, instead of considering the units of study to be the population to be all of the households and estimating the mean of the household per-capita mean daily usage, we should consider the units of study to be household-days, i.e,, each unit is a given day in a given household when its cook-stove is used.  Then the population would be the set of all household-days, and the parameter to be estimated is the mean of the usages over that set.

In this case we would have to consider what sort of sample we have drawn from that population.  Given that we have randomly sampled households and then measured usage for 3-4 days at each household, we are looking at what is known as a "cluster" sample.

Now it is possible to treat a cluster sample as a simple random sample, provided that it is reasonable to believe that the cluster-units---for us: the households in the population---are similar with respect to their per-capita daily usage of wood.

But are the households similar?  One way to investigate this question is to make use of the fact that if the households *were* similar, then each one of the observed per-capita daily measurments could have been observed at any of the houses in the sample---not just at the house where it was actually observed.

in the app below, each time the user presses the action button the observed measurements in the actual study are scrambled randomly among the sample households.  Each household $h_i$, where $1 \leq i \leq 16$, gets the same number $J_i$ of measurements that it had in the actual study, but these $J_i$ measurements are a random sample form the 57 measurments in the study.  The app then computes the average of the measurements for each household and makes a density plot (right column in the main panel) of these 16 averages.  For comparison, a density plot of the 16 averages in the actual study is shown in the left column of the main panel.

Try the app many times, comparing the right and left columns as you go.

<!-- Eivory does this app-->

```{r sampling, echo=FALSE}
# shinyAppDir(
#   appDir = "sampling",
#   options = list(
#     width = "100%", height = 550
#   )
# )
```

You will probably notice that, on the whole the averages from scrambled measurements are much less spread apart from each other than are the averages from the actual study.  This is happening because the households are *not* similar with respect to usage:  some households use more wood per-capita on average than do other houses.

Statisticians might suggest that we quantify the strength of the evidence provided by the data for dis-similarity across households.  One possible way to accomplish this is to compare two models of wood-usage:

* a "null" linear model of usage: a linear model where the response variable is the usage and there are no predictor varaibles;
* a "random-effect" model: a model where the response variable is usage and the predictor variable is the household at which the usage was observed, with the mean usage for each houshold assumed to be normally distributed with mean $\mu$ and some unknown standard deviation).

The comparison is carried out through an *analysis of variance*, which compares how well each model does at the task of "fitting" to the observed data.  When we do the analysis of variance with the R-package **nlme**, we get the following results:

```{r}
mod_null <- lm(wood ~ 1, data = all_meas)
mod_rf <- lme(wood ~ 1, random = ~ 1 | house, data = all_meas)
res <- anova(mod_rf, mod_null)
df <- as.data.frame(res)
knitr::kable(df[, -(1:5)])
```

Among other things, the model computes the natural logarithm of the likelihood of getting the observed data, under each of the model assumptions.  It then states the ratio of these log-likelihoods (log-likelihood for the random-effect model divided by log-likelihood for the null model) .

We see that the ratio is approximately `r round(res$L.Ratio[2], 3)`, quite a large value.  In fact, if the households in the population are in fact uniform with respect to mean daily per-capita usage of wood, then the probabilty of getting that ratio or higher is extremely small:  less than 0.0001 in fact.

We conclude that the data provide extrememly strong evidence that households in the population are dis-similar in their wood-usage.  Thus it is better to choose households as our units of study and to attempt estimate $\mu$, the mean of their mean daily per-capita usages.
